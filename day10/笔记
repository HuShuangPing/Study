失控  kk ,必然

浪潮之巅  ，数学之美


线程 内存共享
线程同时修改同一份数据时必须加锁，mutex互斥锁
递归锁

def run(n):
  print('run thread...')




for i in range(10):
    t = threading.Thread(target=run, args=(n,))
    t.setDaemon(True)
    t.start()


print 'master is done....'

守护线程(slave) 服务与非守护线程(master)


进程 至少包含一个线程


queue
   解耦，使程序直接实现松耦合，
   提高处理效率 ，

   FIFO = first in first out
   LIFO = last in first out



Python中多进程运行时利用CPU上下文切换
io 操作不占用cpu
计算占用cpu , 如：1+1
python多线程 不适合cpu密集操作型的任务，适合io操作密集型的任务


multiprocess  多线程

进程间通信需要一个中介
1.Queue  \ Pipe 只是实现进程间数据的传递
2.Manager 实现了进程间数据的共享，即多个进程可以修改同一份数据

协程:拥有自己的寄存器上下文和栈，协程调度切换时，将寄存器上下文和栈报错到其他地方，再切回来的时候恢复寄存器和栈
所以协程能保留上衣调用时状态（即所有局部状态的一个特定组合）每次过程重入是，进入上次调用的状态
1.无需线程上文切换的开销
2.无需原子操作锁定及同步的开销
3.方便切换控制流，简化变成模型
4.高并发+高扩展性+低成本：一个CPU支持上万个协程都不是问题，所以很适合高并发处理
协程是在单线程中实现的，单线程是串行的，对数据进行修改时，无需加锁

无法利用多核资源，协程的本质是个单线程，不能同时将单个CPU的多核用
协程需要和进程配合才能运行在多核CPU上
进行阻塞操作（如IO时）会阻塞掉整个程序

在单线程下实现并发，遇到io操作就切换
Greenlet---是已经封装好的协程



论事件驱动与异步IO
  (1)大多数网络服务器采用的方式：
     每收到一个请求，放入一个事件列表，让主进程通过非阻塞I/O方式来处理请求
  (2)事件驱动模型大体思路如下：
    1. 有一个事件（消息）队列；
    2. 鼠标按下时，往这个队列中增加一个点击事件（消息）；
    3. 有个循环，不断从队列取出事件，根据不同的事件，调用不同的函数，如onClick()、onKeyDown()等；
    4. 事件（消息）一般都各自保存各自的处理函数指针，这样，每个消息都有独立的处理函数；

   特点是包含一个事件循环，当外部事件发生时使用回调机制来触发相应的处理。回调函数执行什么可以自己定义
   另外两种常见的编程范式是（单线程）同步以及多线程编程。

I/O 多路复用
  1.基本概念
     （1）用户空间与内核空间
         现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。
         操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。
         为了保证用户进程不能直接操作内核（kernel），保证内核的安全，
         操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。
         针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），
         供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。
    （2）进程切换
    （3）进程阻塞
         正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，
         则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。
         可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。
         当进程进入阻塞状态，是不占用CPU资源的。
    （4）文件描述符id
        实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。
        当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。
        在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。
        但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。
    (5)缓存 I/O
       存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。
       在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，
       也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。
        缓存 I/O 的缺点：
         数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，
         这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。
  2.I/O模式
    对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，
    然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。
    所以说，当一个read操作发生时，它会经历两个阶段：
        1. 等待数据准备 (Waiting for the data to be ready)
        2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

    正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。
    - 阻塞 I/O（blocking IO）
    - 非阻塞 I/O（nonblocking IO）
    - I/O 多路复用（ IO multiplexing）
    - 信号驱动 I/O（ signal driven IO）
    - 异步 I/O（asynchronous IO）
